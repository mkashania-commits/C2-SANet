{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3254d0-ea03-452a-8705-2a7563ca0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import InputSpec\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import constraints\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8164f90-53ec-4204-9617-dd29f9012afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Add\n",
    "def concatenate_with(real1, imag1,real2,imag2):\n",
    "    \n",
    "    real_concat = Concatenate(axis=-1)([real1, real2])\n",
    "    imag_concat = Concatenate(axis=-1)([imag1, imag2])\n",
    "    return real_concat, imag_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88739925-d8dd-4cd8-86fa-af8bc66b3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_with(real1, imag1,real2,imag2):\n",
    "    real_added = Add()([real1, real2])\n",
    "    imag_added = Add()([imag1, imag2])\n",
    "    return real_added, imag_added\n",
    "#from tensorflow.keras.layers import Add\n",
    "\n",
    "def add_with_new(real1, imag1, real2, imag2, name=None):\n",
    "    real_added = Add(name=None if name is None else name + \"_real\")([real1, real2])\n",
    "    imag_added = Add(name=None if name is None else name + \"_imag\")([imag1, imag2])\n",
    "    return real_added, imag_added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ece7e-1c8d-4f62-8234-3ba14e5fbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexUpSampling2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, size=(2, 2), interpolation='bilinear'):\n",
    "        super(ComplexUpSampling2D, self).__init__()\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.real_upsampling = tf.keras.layers.UpSampling2D(size=self.size, interpolation=self.interpolation)\n",
    "        self.imag_upsampling = tf.keras.layers.UpSampling2D(size=self.size, interpolation=self.interpolation)\n",
    "        super(ComplexUpSampling2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_upsampling(real_inputs)\n",
    "        imag_outputs = self.imag_upsampling(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919389e-02c8-4e49-a004-cf3170509f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'COMPLEX DENSE'\n",
    "class complex_Dense(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    tf.keras.layers.Dense(\n",
    "        units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None,\n",
    "        activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\n",
    "        **kwargs\n",
    "    )\n",
    "    \"\"\"\n",
    "    def __init__ (self, units = 512,\n",
    "                        activation = None,\n",
    "                        use_bias   = True, \n",
    "                        kernel_initializer = 'glorot_uniform',\n",
    "                        bias_initializer   = 'zeros', \n",
    "                        kernel_regularizer = None, \n",
    "                        bias_regularizer   = None,\n",
    "                        activity_regularizer = None, \n",
    "                        kernel_constraint    = None, \n",
    "                        bias_constraint      = None):\n",
    "        super(complex_Dense, self).__init__()\n",
    "        self.units                = units\n",
    "        self.activation           = activation\n",
    "        self.use_bias             = use_bias\n",
    "        self.kernel_initializer   = kernel_initializer\n",
    "        self.bias_initializer     = bias_initializer\n",
    "        self.kernel_regularizer   = kernel_regularizer\n",
    "        self.bias_regularizer     = bias_regularizer\n",
    "        self.activity_regularizer = activity_regularizer\n",
    "        self.kernel_constraint    = kernel_constraint\n",
    "        self.bias_constraint      = bias_constraint\n",
    "        \n",
    "        \n",
    "    def build (self, inputs_shape):\n",
    "        self.real_Dense = tf.keras.layers.Dense(units = self.units, \n",
    "                                                activation = self.activation, \n",
    "                                                use_bias   = self.use_bias, \n",
    "                                                kernel_initializer = self.kernel_initializer,\n",
    "                                                bias_initializer   = self.bias_initializer, \n",
    "                                                kernel_regularizer = self.kernel_regularizer,\n",
    "                                                bias_regularizer   = self.bias_regularizer,\n",
    "                                                activity_regularizer = self.activity_regularizer, \n",
    "                                                kernel_constraint    = self.kernel_constraint,\n",
    "                                                bias_constraint      = self.bias_constraint)\n",
    "        \n",
    "        self.imag_Dense = tf.keras.layers.Dense(units = self.units, \n",
    "                                                activation = self.activation, \n",
    "                                                use_bias   = self.use_bias, \n",
    "                                                kernel_initializer = self.kernel_initializer,\n",
    "                                                bias_initializer   = self.bias_initializer, \n",
    "                                                kernel_regularizer = self.kernel_regularizer,\n",
    "                                                bias_regularizer   = self.bias_regularizer,\n",
    "                                                activity_regularizer = self.activity_regularizer, \n",
    "                                                kernel_constraint    = self.kernel_constraint,\n",
    "                                                bias_constraint      = self.bias_constraint)\n",
    "        \n",
    "        super(complex_Dense, self).build(inputs_shape)\n",
    "        \n",
    "\n",
    "    def call (self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_Dense(real_inputs) - self.imag_Dense(imag_inputs)\n",
    "        imag_outputs = self.imag_Dense(real_inputs) + self.real_Dense(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "\n",
    "'COMPLEX CONVOLUTION 2D'\n",
    "class complex_Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                filters = 32,\n",
    "                kernel_size = (3, 3), \n",
    "                strides = (1, 1), \n",
    "                padding = \"same\",\n",
    "                activation = None,\n",
    "                use_bias   = True,\n",
    "                kernel_initializer = 'glorot_uniform',\n",
    "                bias_initializer   = 'zeros'):\n",
    "        super(complex_Conv2D, self).__init__()\n",
    "        self.filters            = filters\n",
    "        self.kernel_size        = kernel_size\n",
    "        self.strides            = strides\n",
    "        self.padding            = padding\n",
    "        self.activation         = activation\n",
    "        self.use_bias           = use_bias\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer   = bias_initializer\n",
    "        \n",
    "    def build (self, inputs_shape):\n",
    "        self.real_Conv2D = tf.keras.layers.Conv2D(filters = self.filters//2,\n",
    "                                                kernel_size = self.kernel_size, \n",
    "                                                strides = self.strides,\n",
    "                                                padding = self.padding,\n",
    "                                                activation = self.activation,\n",
    "                                                use_bias = self.use_bias,\n",
    "                                                kernel_initializer = self.kernel_initializer,\n",
    "                                                bias_initializer = self.bias_initializer) \n",
    "\n",
    "        self.imag_Conv2D = tf.keras.layers.Conv2D(filters = self.filters//2,\n",
    "                                                kernel_size = self.kernel_size, \n",
    "                                                strides = self.strides,\n",
    "                                                padding = self.padding,\n",
    "                                                activation = self.activation,\n",
    "                                                use_bias = self.use_bias,\n",
    "                                                kernel_initializer = self.kernel_initializer,\n",
    "                                                bias_initializer = self.bias_initializer) \n",
    "        \n",
    "        super(complex_Conv2D, self).build(inputs_shape)\n",
    "\n",
    "        \n",
    "    def call(self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_Conv2D(real_inputs) - self.imag_Conv2D(imag_inputs)\n",
    "        imag_outputs = self.imag_Conv2D(real_inputs) + self.real_Conv2D(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "class complex_Conv2D_new(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 filters=32,\n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\",\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 name=None):  # Add name here\n",
    "        super(complex_Conv2D_new, self).__init__(name=name)  # Pass name to base class\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        \n",
    "    def build(self, inputs_shape):\n",
    "        self.real_Conv2D = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters // 2,\n",
    "            kernel_size=self.kernel_size, \n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            activation=self.activation,\n",
    "            use_bias=self.use_bias,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "            bias_initializer=self.bias_initializer\n",
    "        )\n",
    "        self.imag_Conv2D = tf.keras.layers.Conv2D(\n",
    "            filters=self.filters // 2,\n",
    "            kernel_size=self.kernel_size, \n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            activation=self.activation,\n",
    "            use_bias=self.use_bias,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "            bias_initializer=self.bias_initializer\n",
    "        )\n",
    "        super(complex_Conv2D_new, self).build(inputs_shape)\n",
    "\n",
    "    def call(self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_Conv2D(real_inputs) - self.imag_Conv2D(imag_inputs)\n",
    "        imag_outputs = self.imag_Conv2D(real_inputs) + self.real_Conv2D(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "'COMPLEX CONV 2D TRANSPOSE'\n",
    "class complex_Conv2DTranspose (tf.keras.layers.Layer):\n",
    "    def __init__(self,  filters = 32,\n",
    "                        kernel_size = (3, 3), \n",
    "                        strides = (2, 2), \n",
    "                        padding = \"same\",\n",
    "                        activation = None,\n",
    "                        use_bias   = True,\n",
    "                        kernel_initializer = 'glorot_uniform',\n",
    "                        bias_initializer   = 'zeros'):\n",
    "        super(complex_Conv2DTranspose, self).__init__()\n",
    "        self.filters            = filters\n",
    "        self.kernel_size        = kernel_size\n",
    "        self.strides            = strides\n",
    "        self.padding            = padding\n",
    "        self.activation         = activation\n",
    "        self.use_bias           = use_bias\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer   = bias_initializer\n",
    "        \n",
    "        \n",
    "    def build (self, inputs_shape):\n",
    "        self.real_Conv2DTranspose = tf.keras.layers.Conv2DTranspose(filters = self.filters,\n",
    "                                                        kernel_size = self.kernel_size, \n",
    "                                                        strides = self.strides, \n",
    "                                                        padding = self.padding, \n",
    "                                                        activation = self.activation, \n",
    "                                                        use_bias = self.use_bias,\n",
    "                                                        kernel_initializer = self.kernel_initializer, \n",
    "                                                        bias_initializer = self.bias_initializer)\n",
    "\n",
    "        self.imag_Conv2DTranspose = tf.keras.layers.Conv2DTranspose(filters = self.filters,\n",
    "                                                        kernel_size = self.kernel_size, \n",
    "                                                        strides = self.strides, \n",
    "                                                        padding = self.padding, \n",
    "                                                        activation = self.activation, \n",
    "                                                        use_bias = self.use_bias,\n",
    "                                                        kernel_initializer = self.kernel_initializer, \n",
    "                                                        bias_initializer = self.bias_initializer)\n",
    "        \n",
    "        super(complex_Conv2DTranspose, self).build(inputs_shape)\n",
    "\n",
    "        \n",
    "    def call (self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_Conv2DTranspose(real_inputs) - self.imag_Conv2DTranspose(imag_inputs)\n",
    "        imag_outputs = self.imag_Conv2DTranspose(real_inputs) + self.real_Conv2DTranspose(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "\n",
    "'COMPLEX CONV !D'\n",
    "class complex_Conv1D (tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    tf.keras.layers.Conv1D(\n",
    "    filters, kernel_size, strides=1, padding='valid', data_format='channels_last',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    "    )\n",
    "    \"\"\"\n",
    "    def __init__ (self,\n",
    "                filters, \n",
    "                kernel_size, \n",
    "                strides = 1, \n",
    "                padding = 'same', \n",
    "                data_format = 'channels_last',\n",
    "                dilation_rate = 1,\n",
    "                groups = 1, \n",
    "                activation = None, \n",
    "                use_bias = True,\n",
    "                kernel_initializer = 'glorot_uniform', \n",
    "                bias_initializer = 'zeros',\n",
    "                kernel_regularizer = None, \n",
    "                bias_regularizer = None, \n",
    "                activity_regularizer = None,\n",
    "                kernel_constraint = None,\n",
    "                bias_constraint = None):\n",
    "        super(complex_Conv1D, self).__init__()\n",
    "        self.filters              = filters\n",
    "        self.kernel_size          = kernel_size\n",
    "        self.strides              = strides\n",
    "        self.padding              = padding\n",
    "        self.activation           = activation\n",
    "        self.use_bias             = use_bias\n",
    "        self.kernel_initializer   = kernel_initializer\n",
    "        self.bias_initializer     = bias_initializer\n",
    "        self.kernel_regularizer   = kernel_regularizer\n",
    "        self.bias_regularizer     = bias_regularizer\n",
    "        self.activity_regularizer = activity_regularizer\n",
    "        self.kernel_constraint    = kernel_constraint\n",
    "        self.bias_constraint      = bias_constraint\n",
    "\n",
    "        self.real_Conv1D = tf.keras.layers.Conv1D(filters = self.filters, \n",
    "                                                kernel_size = self.kernel_size, \n",
    "                                                strides = self.strides, \n",
    "                                                padding = self.padding, \n",
    "                                                activation = None, \n",
    "                                                use_bias = self.use_bias,\n",
    "                                                kernel_initializer = self.kernel_initializer, \n",
    "                                                bias_initializer = self.bias_initializer,\n",
    "                                                kernel_regularizer = self.kernel_regularizer, \n",
    "                                                bias_regularizer = self.bias_regularizer, \n",
    "                                                activity_regularizer = self.activity_regularizer,\n",
    "                                                kernel_constraint = self.kernel_constraint, \n",
    "                                                bias_constraint = self.bias_constraint)\n",
    "        \n",
    "        self.imag_Conv1D = tf.keras.layers.Conv1D(filters = self.filters, \n",
    "                                                kernel_size = self.kernel_size, \n",
    "                                                strides = self.strides, \n",
    "                                                padding = self.padding, \n",
    "                                                activation = None, \n",
    "                                                use_bias = self.use_bias,\n",
    "                                                kernel_initializer = self.kernel_initializer, \n",
    "                                                bias_initializer = self.bias_initializer,\n",
    "                                                kernel_regularizer = self.kernel_regularizer, \n",
    "                                                bias_regularizer = self.bias_regularizer, \n",
    "                                                activity_regularizer = self.activity_regularizer,\n",
    "                                                kernel_constraint = self.kernel_constraint, \n",
    "                                                bias_constraint = self.bias_constraint)\n",
    "\n",
    "    \n",
    "    def call (self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_Conv1D(real_inputs) - self.imag_Conv1D(imag_inputs)\n",
    "        imag_outputs = self.imag_Conv1D(real_inputs) + self.real_Conv1D(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "\n",
    "'COMPLEX CONV !D'\n",
    "class complex_Conv1DTranspose (tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    tf.keras.layers.Conv1D(\n",
    "    filters, kernel_size, strides=1, padding='valid', data_format='channels_last',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    "    )\n",
    "    \"\"\"\n",
    "    def __init__ (self,\n",
    "                filters, \n",
    "                kernel_size, \n",
    "                strides = 1, \n",
    "                padding = 'same', \n",
    "                data_format = 'channels_last',\n",
    "                dilation_rate = 1,\n",
    "                groups = 1, \n",
    "                activation = None, \n",
    "                use_bias = True,\n",
    "                kernel_initializer = 'glorot_uniform', \n",
    "                bias_initializer = 'zeros',\n",
    "                kernel_regularizer = None, \n",
    "                bias_regularizer = None, \n",
    "                activity_regularizer = None,\n",
    "                kernel_constraint = None,\n",
    "                bias_constraint = None):\n",
    "        super(complex_Conv1DTranspose, self).__init__()\n",
    "        self.filters              = filters\n",
    "        self.kernel_size          = kernel_size\n",
    "        self.strides              = strides\n",
    "        self.padding              = padding\n",
    "        self.activation           = activation\n",
    "        self.use_bias             = use_bias\n",
    "        self.kernel_initializer   = kernel_initializer\n",
    "        self.bias_initializer     = bias_initializer\n",
    "        self.kernel_regularizer   = kernel_regularizer\n",
    "        self.bias_regularizer     = bias_regularizer\n",
    "        self.activity_regularizer = activity_regularizer\n",
    "        self.kernel_constraint    = kernel_constraint\n",
    "        self.bias_constraint      = bias_constraint\n",
    "\n",
    "        self.real_Conv1D = tf.keras.layers.Conv1DTranspose(filters = self.filters, \n",
    "                                                        kernel_size = self.kernel_size, \n",
    "                                                        strides = self.strides, \n",
    "                                                        padding = self.padding, \n",
    "                                                        activation = None, \n",
    "                                                        use_bias = self.use_bias,\n",
    "                                                        kernel_initializer = self.kernel_initializer, \n",
    "                                                        bias_initializer = self.bias_initializer,\n",
    "                                                        kernel_regularizer = self.kernel_regularizer, \n",
    "                                                        bias_regularizer = self.bias_regularizer, \n",
    "                                                        activity_regularizer = self.activity_regularizer,\n",
    "                                                        kernel_constraint = self.kernel_constraint, \n",
    "                                                        bias_constraint = self.bias_constraint)\n",
    "        \n",
    "        self.imag_Conv1D = tf.keras.layers.Conv1DTranspose(filters = self.filters, \n",
    "                                                        kernel_size = self.kernel_size, \n",
    "                                                        strides = self.strides, \n",
    "                                                        padding = self.padding, \n",
    "                                                        activation = None, \n",
    "                                                        use_bias = self.use_bias,\n",
    "                                                        kernel_initializer = self.kernel_initializer, \n",
    "                                                        bias_initializer = self.bias_initializer,\n",
    "                                                        kernel_regularizer = self.kernel_regularizer, \n",
    "                                                        bias_regularizer = self.bias_regularizer, \n",
    "                                                        activity_regularizer = self.activity_regularizer,\n",
    "                                                        kernel_constraint = self.kernel_constraint, \n",
    "                                                        bias_constraint = self.bias_constraint)\n",
    "\n",
    "    \n",
    "    def call (self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_Conv1D(real_inputs) - self.imag_Conv1D(imag_inputs)\n",
    "        imag_outputs = self.imag_Conv1D(real_inputs) + self.real_Conv1D(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "class ComplexMaxPool2D_mag(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size=(2, 2), strides=(2, 2)):\n",
    "        super(ComplexMaxPool2D_mag, self).__init__()\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def call(self, real_inputs, imag_inputs):\n",
    "        # Compute magnitude\n",
    "        magnitude = tf.sqrt(real_inputs**2 + imag_inputs**2)\n",
    "\n",
    "        # Perform max pooling on the magnitude and get indices\n",
    "        magnitude_pooled, argmax_indices = tf.nn.max_pool_with_argmax(\n",
    "            magnitude,\n",
    "            ksize=self.pool_size,\n",
    "            strides=self.strides,\n",
    "            padding=\"VALID\",\n",
    "            include_batch_in_index=True\n",
    "        )\n",
    "\n",
    "        # Flatten inputs to use gather for selecting real & imaginary parts\n",
    "        real_flattened = tf.reshape(real_inputs, [-1])\n",
    "        imag_flattened = tf.reshape(imag_inputs, [-1])\n",
    "\n",
    "        # Gather corresponding real and imaginary parts using indices\n",
    "        real_pooled = tf.gather(real_flattened, argmax_indices)\n",
    "        imag_pooled = tf.gather(imag_flattened, argmax_indices)\n",
    "\n",
    "        return real_pooled, imag_pooled\n",
    "\n",
    "'COMPLEX POOLING'\n",
    "class complex_MaxPool2D (tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size = (2, 2)):\n",
    "        super(complex_MaxPool2D, self).__init__()\n",
    "        self.pool_size = pool_size\n",
    "       \n",
    "    def build (self, inputs_shape):\n",
    "        self.real_maxpooling = tf.keras.layers.MaxPool2D(pool_size = self.pool_size\n",
    "                                                       )\n",
    "        \n",
    "        self.imag_maxpooling = tf.keras.layers.MaxPool2D(pool_size = self.pool_size\n",
    "                                                        )\n",
    "        \n",
    "        super(complex_MaxPool2D, self).build(inputs_shape)\n",
    "        \n",
    "    def call (self, real_inputs, imag_inputs):\n",
    "        real_outputs = self.real_maxpooling(real_inputs)\n",
    "        imag_outputs = self.imag_maxpooling(imag_inputs)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "\n",
    "'https://github.com/fchollet/keras/blob/master/keras/layers/normalization.py'\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE INITIALIZERS\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "def sqrt_init(shape, dtype = None):\n",
    "    value = (1 / np.sqrt(2)) * K.ones(shape)\n",
    "    return value\n",
    "\n",
    "\n",
    "def sanitizedInitGet(init):\n",
    "    if init in [\"sqrt_init\"]:\n",
    "        return sqrt_init\n",
    "    else:\n",
    "        return initializers.get(init)\n",
    "\n",
    "\n",
    "def sanitizedInitSer(init):\n",
    "    if init in [sqrt_init]:\n",
    "        return \"sqrt_init\"\n",
    "    else:\n",
    "        return initializers.serialize(init)\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE NAIVE BATCH NORMALIZATION\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "class complex_NaiveBatchNormalization (tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "                                        beta_initializer='zeros', gamma_initializer='ones',\n",
    "                                        moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
    "                                        beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
    "                                        gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.99,\n",
    "                                        fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
    "                                        **kwargs)\n",
    "    \"\"\"\n",
    "    def __init__ (self, axis = -1, \n",
    "                        momentum = 0.99, \n",
    "                        epsilon = 0.001, \n",
    "                        center = True, \n",
    "                        scale = True,\n",
    "                        beta_initializer = 'zeros', \n",
    "                        gamma_initializer = 'ones',\n",
    "                        moving_mean_initializer = 'zeros',\n",
    "                        moving_variance_initializer = 'ones',\n",
    "                        beta_regularizer = None, \n",
    "                        gamma_regularizer = None, \n",
    "                        beta_constraint = None,\n",
    "                        gamma_constraint = None,\n",
    "                        renorm = False,\n",
    "                        renorm_clipping = None, \n",
    "                        renorm_momentum = 0.99,\n",
    "                        fused = None, \n",
    "                        trainable = True, \n",
    "                        virtual_batch_size = None,\n",
    "                        adjustment = None,\n",
    "                        **kwargs):\n",
    "        super(complex_NaiveBatchNormalization, self).__init__()\n",
    "\n",
    "        self.momentum = momentum\n",
    "        self.epsilon  = epsilon\n",
    "        self.center   = center\n",
    "        self.scale    = scale \n",
    "        self.beta_initializer            = beta_initializer\n",
    "        self.gamma_initializer           = gamma_initializer\n",
    "        self.moving_mean_initializer     = moving_mean_initializer\n",
    "        self.moving_variance_initializer = moving_variance_initializer\n",
    "        self.beta_regularizer            = beta_regularizer\n",
    "        self.gamma_regularizer           = gamma_regularizer\n",
    "        self.beta_constraint             = beta_constraint\n",
    "        self.gamma_constraint            = gamma_constraint\n",
    "        self.renorm                      = renorm\n",
    "        self.renorm_clipping             = renorm_clipping\n",
    "        self.renorm_momentum             = renorm_momentum\n",
    "        self.fused                       = fused\n",
    "        self.trainable                   = trainable\n",
    "        self.virtual_batch_size          = virtual_batch_size\n",
    "        self.adjustment                  = adjustment\n",
    "\n",
    "        self.real_batchnormalization = tf.keras.layers.BatchNormalization(momentum = self.momentum,\n",
    "                                                                        epsilon = self.epsilon,\n",
    "                                                                        center = self.center,\n",
    "                                                                        scale = self.scale,\n",
    "                                                                        beta_initializer = self.beta_initializer,\n",
    "                                                                        gamma_initializer = self.gamma_initializer,\n",
    "                                                                        moving_mean_initializer = self.moving_mean_initializer,\n",
    "                                                                        moving_variance_initializer = self.moving_variance_initializer,\n",
    "                                                                        beta_regularizer = self.beta_regularizer,\n",
    "                                                                        gamma_regularizer = self.gamma_regularizer,\n",
    "                                                                        beta_constraint = self.beta_constraint,\n",
    "                                                                        gamma_constraint = self.gamma_constraint,\n",
    "                                                                        renorm = self.renorm,\n",
    "                                                                        renorm_clipping = self.renorm_clipping,\n",
    "                                                                        renorm_momentum = self.renorm_momentum,\n",
    "                                                                        fused = self.fused,\n",
    "                                                                        trainable = self.trainable,\n",
    "                                                                        virtual_batch_size = self.virtual_batch_size,\n",
    "                                                                        adjustment = self.adjustment)\n",
    "\n",
    "        self.imag_batchnormalization = tf.keras.layers.BatchNormalization(momentum = self.momentum,\n",
    "                                                                        epsilon = self.epsilon,\n",
    "                                                                        center = self.center,\n",
    "                                                                        scale = self.scale,\n",
    "                                                                        beta_initializer = self.beta_initializer,\n",
    "                                                                        gamma_initializer = self.gamma_initializer,\n",
    "                                                                        moving_mean_initializer = self.moving_mean_initializer,\n",
    "                                                                        moving_variance_initializer = self.moving_variance_initializer,\n",
    "                                                                        beta_regularizer = self.beta_regularizer,\n",
    "                                                                        gamma_regularizer = self.gamma_regularizer,\n",
    "                                                                        beta_constraint = self.beta_constraint,\n",
    "                                                                        gamma_constraint = self.gamma_constraint,\n",
    "                                                                        renorm = self.renorm,\n",
    "                                                                        renorm_clipping = self.renorm_clipping,\n",
    "                                                                        renorm_momentum = self.renorm_momentum,\n",
    "                                                                        fused = self.fused,\n",
    "                                                                        trainable = self.trainable,\n",
    "                                                                        virtual_batch_size = self.virtual_batch_size,\n",
    "                                                                        adjustment = self.adjustment)\n",
    "        \n",
    "\n",
    "    def call (self, real_inputs, imag_inputs, training = True):\n",
    "        real_outputs = self.real_batchnormalization (real_inputs, training = training)\n",
    "        imag_outputs = self.imag_batchnormalization (imag_inputs, training = training)\n",
    "        return real_outputs, imag_outputs\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE COMPLEX STANDARDIZATION\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "def complex_standardization (input_centred, Vrr, Vii, Vri, layernorm = False, axis = -1):\n",
    "    \"\"\"Complex Standardization of input\n",
    "    \n",
    "    Arguments:\n",
    "        input_centred -- Input Tensor\n",
    "        Vrr -- Real component of covariance matrix V\n",
    "        Vii -- Imaginary component of covariance matrix V\n",
    "        Vri -- Non-diagonal component of covariance matrix V\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        layernorm {bool} -- Normalization (default: {False})\n",
    "        axis {int} -- Axis for Standardization (default: {-1})\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Mismatched dimensoins\n",
    "    \n",
    "    Returns:\n",
    "        Complex standardized input\n",
    "\n",
    "    We require the covariance matrix's inverse square root. That first\n",
    "    requires square rooting, followed by inversion (I do this in that order\n",
    "    because during the computation of square root we compute the determinant\n",
    "    we'll need for inversion as well).\n",
    "\n",
    "    The square root matrix could now be explicitly formed as\n",
    "          [ Vrr+s Vri   ]\n",
    "    (1/t) [ Vir   Vii+s ]\n",
    "    https://en.wikipedia.org/wiki/Square_root_of_a_2_by_2_matrix\n",
    "    but we don't need to do this immediately since we can also simultaneously\n",
    "    invert. We can do this because we've already computed the determinant of\n",
    "    the square root matrix, and can thus invert it using the analytical\n",
    "    solution for 2x2 matrices\n",
    "         [ A B ]             [  D  -B ]\n",
    "    inv( [ C D ] ) = (1/det) [ -C   A ]\n",
    "    http://mathworld.wolfram.com/MatrixInverse.html\n",
    "    Thus giving us\n",
    "              [  Vii+s  -Vri   ]\n",
    "    (1/s)(1/t)[ -Vir     Vrr+s ]\n",
    "    So we proceed as follows:\n",
    "\n",
    "    And we have computed the inverse square root matrix W = sqrt(V)!\n",
    "    Normalization. We multiply, x_normalized = W.x.\n",
    "\n",
    "    The returned result will be a complex standardized input\n",
    "    where the real and imaginary parts are obtained as follows:\n",
    "    x_real_normed = Wrr * x_real_centred + Wri * x_imag_centred\n",
    "    x_imag_normed = Wri * x_real_centred + Wii * x_imag_centred\n",
    "\n",
    "      Wrr * x_real_centered | Wii * x_imag_centered\n",
    "    + Wri * x_imag_centered | Wri * x_real_centered\n",
    "    -----------------------------------------------\n",
    "    = output\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    [Batch_size, height, width, channels]\n",
    "    ndim(input_centred) == 4\n",
    "        if ndim == 2:\n",
    "            Dense Layer (None, Node)\n",
    "        if ndim == 3:\n",
    "            Conv1D Layer (None, filters, channels)\n",
    "        if ndim == 4:\n",
    "            Conv2D Layer (None, height, width, channels)\n",
    "    shape(input_centred) == [2, 256, 32, 16] --> [2, 256, 32, 8] is real, [2, 256, 32, 8] is imag\n",
    "    shape(input_centred)[axis = -1] == 16\n",
    "    \n",
    "    variances_broadcast는 채널의 갯수에 의존\n",
    "    \"\"\"\n",
    "    ndim      = K.ndim(input_centred) \n",
    "    input_dim = K.shape(input_centred)[axis] // 2\n",
    "\n",
    "    variances_broadcast = [1] * ndim\n",
    "    variances_broadcast[axis] = input_dim\n",
    "\n",
    "    if layernorm:\n",
    "        variances_broadcast[0] = K.shape(input_centred)[0]\n",
    "\n",
    "    tau   = Vrr + Vii\n",
    "    delta = (Vrr * Vii) - (Vri ** 2)\n",
    "\n",
    "    s = K.sqrt(delta)\n",
    "    t = K.sqrt(tau + 2 * s)\n",
    "\n",
    "    inverse_st = 1.0 / (s * t)\n",
    "    Wrr = (Vii + s) * inverse_st\n",
    "    Wii = (Vrr + s) * inverse_st\n",
    "    Wri = -Vri * inverse_st\n",
    "\n",
    "    broadcast_Wrr = K.reshape(Wrr, variances_broadcast)\n",
    "    broadcast_Wri = K.reshape(Wri, variances_broadcast)\n",
    "    broadcast_Wii = K.reshape(Wii, variances_broadcast)\n",
    "\n",
    "    cat_W_4_real  = K.concatenate([broadcast_Wrr, broadcast_Wii], axis = axis)\n",
    "    cat_W_4_imag  = K.concatenate([broadcast_Wri, broadcast_Wri], axis = axis)\n",
    "\n",
    "    if (axis == 1 and ndim != 3) or ndim == 2:\n",
    "        centred_real = input_centred[:, :input_dim]\n",
    "        centred_imag = input_centred[:, input_dim:]\n",
    "    \n",
    "    elif ndim == 3:\n",
    "        centred_real = input_centred[:, :, :input_dim]\n",
    "        centred_imag = input_centred[:, :, input_dim:]\n",
    "\n",
    "    elif ndim == 4:\n",
    "        centred_real = input_centred[:, :, :, :input_dim]\n",
    "        centred_imag = input_centred[:, :, :, input_dim:]\n",
    "\n",
    "    rolled_input = K.concatenate([centred_imag, centred_real], axis = axis)\n",
    "\n",
    "    'wrr real + wri imag, wri real + wii imag'\n",
    "    output = cat_W_4_real * input_centred + cat_W_4_imag * rolled_input\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE COMPLEX BATCH NORMALIZATION\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "def complex_batchnorm (input_centred, Vrr, Vii, Vri, beta, gamma_rr, gamma_ri, gamma_ii, scale = True, center = True, layernorm = False, axis = -1):\n",
    "    \"\"\"Complex Batch Normalization\n",
    "    \n",
    "    Arguments:\n",
    "        input_centred -- input data\n",
    "        Vrr -- Real component of covariance matrix V\n",
    "        Vii -- Imaginary component of covariance matrix V\n",
    "        Vri -- Non-diagonal component of covariance matrix V\n",
    "        beta -- Lernable shift parameter beta\n",
    "        gamma_rr -- Scaling parameter gamma - rr component of 2x2 matrix\n",
    "        gamma_ri -- Scaling parameter gamma - ri component of 2x2 matrix\n",
    "        gamma_ii -- Scaling parameter gamma - ii component of 2x2 matrix\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        scale {bool} {bool} -- Standardization of input  (default: {True})\n",
    "        center {bool} -- Mean-shift correction (default: {True})\n",
    "        layernorm {bool} -- Normalization (default: {False})\n",
    "        axis {int} -- Axis for Standardization (default: {-1})\n",
    "    \n",
    "    Raises: ValueError: Dimonsional mismatch\n",
    "    Returns: Batch-Normalized Input\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(input_centred)\n",
    "    input_dim = K.shape(input_centred)[axis] // 2\n",
    "    if scale:\n",
    "        gamma_broadcast_shape = [1] * ndim\n",
    "        gamma_broadcast_shape[axis] = input_dim\n",
    "    if center:\n",
    "        broadcast_beta_shape = [1] * ndim\n",
    "        broadcast_beta_shape[axis] = input_dim * 2\n",
    "\n",
    "    if scale:\n",
    "        standardized_output = complex_standardization(input_centred, Vrr, Vii, Vri, layernorm, axis = axis)\n",
    "\n",
    "        if (axis == 1 and ndim != 3) or ndim == 2:\n",
    "            centred_real = standardized_output[:, :input_dim]\n",
    "            centred_imag = standardized_output[:, input_dim:]\n",
    "        \n",
    "        elif ndim == 3:\n",
    "            centred_real = standardized_output[:, :, :input_dim]\n",
    "            centred_imag = standardized_output[:, :, input_dim:]\n",
    "\n",
    "        elif ndim == 4:\n",
    "            centred_real = standardized_output[:, :, :, :input_dim]\n",
    "            centred_imag = standardized_output[:, :, :, input_dim:]\n",
    "\n",
    "        rolled_standardized_output = K.concatenate([centred_imag, centred_real], axis = axis)\n",
    "\n",
    "        broadcast_gamma_rr = K.reshape(gamma_rr, gamma_broadcast_shape)\n",
    "        broadcast_gamma_ri = K.reshape(gamma_ri, gamma_broadcast_shape)\n",
    "        broadcast_gamma_ii = K.reshape(gamma_ii, gamma_broadcast_shape)\n",
    "        cat_gamma_4_real   = K.concatenate([broadcast_gamma_rr, broadcast_gamma_ii], axis = axis)\n",
    "        cat_gamma_4_imag   = K.concatenate([broadcast_gamma_ri, broadcast_gamma_ri], axis = axis)\n",
    "\n",
    "        if center:\n",
    "            broadcast_beta = K.reshape(beta, broadcast_beta_shape)\n",
    "            return cat_gamma_4_real * standardized_output + cat_gamma_4_imag * rolled_standardized_output + broadcast_beta\n",
    "        else:\n",
    "            return cat_gamma_4_real * standardized_output + cat_gamma_4_imag * rolled_standardized_output\n",
    "    else:\n",
    "        if center:\n",
    "            broadcast_beta = K.reshape(beta, broadcast_beta_shape)\n",
    "            return input_centred + broadcast_beta\n",
    "        else:\n",
    "            return input_centred\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE complex_Dense\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "class complex_Dense_BatchNorm (tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                axis = -1,\n",
    "                momentum = 0.9,\n",
    "                epsilon = 1e-4,\n",
    "                center = True,\n",
    "                scale = True,\n",
    "                beta_initializer = 'zeros',\n",
    "                gamma_diag_initializer = 'sqrt_init',\n",
    "                gamma_off_initializer = 'zeros',\n",
    "                moving_mean_initializer = 'zeros',\n",
    "                moving_variance_initializer = 'sqrt_init',\n",
    "                moving_covariance_initializer = 'zeros',\n",
    "                beta_regularizer = None,\n",
    "                gamma_diag_regularizer = None,\n",
    "                gamma_off_regularizer = None,\n",
    "                beta_constraint = None,\n",
    "                gamma_diag_constraint = None,\n",
    "                gamma_off_constraint = None,\n",
    "                **kwargs):\n",
    "\n",
    "        super(complex_Dense_BatchNorm, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking              = True\n",
    "        self.axis                          = axis\n",
    "        self.momentum                      = momentum\n",
    "        self.epsilon                       = epsilon\n",
    "        self.center                        = center\n",
    "        self.scale                         = scale\n",
    "        self.beta_initializer              = sanitizedInitGet(beta_initializer)\n",
    "        self.gamma_diag_initializer        = sanitizedInitGet(gamma_diag_initializer)\n",
    "        self.gamma_off_initializer         = sanitizedInitGet(gamma_off_initializer)\n",
    "        self.moving_mean_initializer       = sanitizedInitGet(moving_mean_initializer)\n",
    "        self.moving_variance_initializer   = sanitizedInitGet(moving_variance_initializer)\n",
    "        self.moving_covariance_initializer = sanitizedInitGet(moving_covariance_initializer)\n",
    "        self.beta_regularizer              = regularizers.get(beta_regularizer)\n",
    "        self.gamma_diag_regularizer        = regularizers.get(gamma_diag_regularizer)\n",
    "        self.gamma_off_regularizer         = regularizers.get(gamma_off_regularizer)\n",
    "        self.beta_constraint               = constraints .get(beta_constraint)\n",
    "        self.gamma_diag_constraint         = constraints .get(gamma_diag_constraint)\n",
    "        self.gamma_off_constraint          = constraints .get(gamma_off_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        ndim = len(input_shape)\n",
    "        dim  = input_shape[self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of ' 'input tensor should have a defined dimension ' 'but the layer received an input with shape ' + str(input_shape) + '.')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape), axes={self.axis: dim})\n",
    "        param_shape = (input_shape[self.axis] // 2,)        # Respectively, dim of real == 2, dim of imag == 2\n",
    "\n",
    "        if self.scale:        # Additional parameter\n",
    "            self.gamma_rr   = self.add_weight(shape=param_shape, name='gamma_rr', initializer=self.gamma_diag_initializer, regularizer=self.gamma_diag_regularizer, constraint=self.gamma_diag_constraint)\n",
    "            self.gamma_ii   = self.add_weight(shape=param_shape, name='gamma_ii', initializer=self.gamma_diag_initializer, regularizer=self.gamma_diag_regularizer, constraint=self.gamma_diag_constraint)\n",
    "            self.gamma_ri   = self.add_weight(shape=param_shape, name='gamma_ri', initializer=self.gamma_off_initializer, regularizer=self.gamma_off_regularizer, constraint=self.gamma_off_constraint)\n",
    "            self.moving_Vrr = self.add_weight(shape=param_shape, initializer=self.moving_variance_initializer, name='moving_Vrr', trainable=False)\n",
    "            self.moving_Vii = self.add_weight(shape=param_shape, initializer=self.moving_variance_initializer, name='moving_Vii', trainable=False)\n",
    "            self.moving_Vri = self.add_weight(shape=param_shape, initializer=self.moving_covariance_initializer, name='moving_Vri', trainable=False)\n",
    "        else:\n",
    "            self.gamma_rr   = None\n",
    "            self.gamma_ii   = None\n",
    "            self.gamma_ri   = None\n",
    "            self.moving_Vrr = None\n",
    "            self.moving_Vii = None\n",
    "            self.moving_Vri = None\n",
    "\n",
    "        if self.center:\n",
    "            self.beta        = self.add_weight(shape=(input_shape[self.axis],), name='beta', initializer=self.beta_initializer, regularizer=self.beta_regularizer, constraint=self.beta_constraint)\n",
    "            self.moving_mean = self.add_weight(shape=(input_shape[self.axis],), initializer=self.moving_mean_initializer, name='moving_mean', trainable=False)\n",
    "        else:\n",
    "            self.beta        = None\n",
    "            self.moving_mean = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training = None):\n",
    "\n",
    "        input_shape = K.int_shape(inputs) # (None, Node), Node could be decomposition real parts and imag part :None] == concat(real part, imag part, axis = -1)\n",
    "        ndim        = len(input_shape) # 2\n",
    "\n",
    "        reduction_axes = list(range(ndim)) # If ndim == 4, list(range(ndim)) == [0, 1]\n",
    "        del reduction_axes[self.axis] # --> [0], 즉 배치 사이즈\n",
    "\n",
    "        input_dim = input_shape[self.axis] // 2           # 1\n",
    "        mu        = K.mean(inputs, axis = reduction_axes) # real mu, imag mu\n",
    "\n",
    "        broadcast_mu_shape            = [1] * len(input_shape) # [1, 1]\n",
    "        broadcast_mu_shape[self.axis] = input_shape[self.axis] # [1, input_shape[self.axis]]\n",
    "        broadcast_mu                  = K.reshape(mu, broadcast_mu_shape) # mu shape is [1, 2]\n",
    "\n",
    "        \"\"\"\n",
    "        real parts에는 real mean을 빼고\n",
    "        imag parts에는 imag mean을 뺀다\n",
    "        centred_squared == (x - E(x))^2\n",
    "        \"\"\"\n",
    "        if self.center:\n",
    "            input_centred = inputs - broadcast_mu\n",
    "        else:\n",
    "            input_centred = inputs\n",
    "\n",
    "        centred_squared = input_centred ** 2\n",
    "\n",
    "        'for Dense'\n",
    "        centred_squared_real = centred_squared[:, :input_dim] # real\n",
    "        centred_squared_imag = centred_squared[:, input_dim:] # imag\n",
    "        centred_real = input_centred[:, :input_dim] # real\n",
    "        centred_imag = input_centred[:, input_dim:] # imag\n",
    "\n",
    "        if self.scale:\n",
    "            Vrr = K.mean(centred_squared_real, axis=reduction_axes) + self.epsilon\n",
    "            Vii = K.mean(centred_squared_imag, axis=reduction_axes) + self.epsilon\n",
    "            Vri = K.mean(centred_real * centred_imag, axis=reduction_axes,) # Vri contains the real and imaginary covariance for each feature map.\n",
    "        elif self.center:\n",
    "            Vrr = None\n",
    "            Vii = None\n",
    "            Vri = None\n",
    "        else:\n",
    "            raise ValueError('Error. Both scale and center in batchnorm are set to False.')\n",
    "\n",
    "        \"\"\"\n",
    "        1. Calcultae BatchNormalization for real parts, imag parts of complex numbers\n",
    "        2. If Training == True, Under self.center and self.scale condition, Update parameter moving mean, moving_Vrr, moving_Vii, moving_Vri\n",
    "        \"\"\"\n",
    "        input_bn = complex_batchnorm(input_centred, Vrr, Vii, Vri, self.beta, self.gamma_rr, self.gamma_ri, self.gamma_ii, self.scale, self.center, axis = self.axis)\n",
    "\n",
    "        if training in {0, False}:\n",
    "            return input_bn\n",
    "        else: # traning is True!!!\n",
    "            update_list = []\n",
    "            if self.center:\n",
    "                update_list.append(K.moving_average_update(self.moving_mean, mu, self.momentum))\n",
    "            if self.scale:\n",
    "                update_list.append(K.moving_average_update(self.moving_Vrr, Vrr, self.momentum))\n",
    "                update_list.append(K.moving_average_update(self.moving_Vii, Vii, self.momentum))\n",
    "                update_list.append(K.moving_average_update(self.moving_Vri, Vri, self.momentum))\n",
    "            self.add_update(update_list, inputs)\n",
    "\n",
    "            def normalize_inference():\n",
    "                if self.center:\n",
    "                    inference_centred = inputs - K.reshape(self.moving_mean, broadcast_mu_shape)\n",
    "                else:\n",
    "                    inference_centred = inputs\n",
    "                return complex_batchnorm(inference_centred, \n",
    "                                self.moving_Vrr, self.moving_Vii, self.moving_Vri, self.beta, \n",
    "                                self.gamma_rr, self.gamma_ri, self.gamma_ii, self.scale, self.center, axis = self.axis)\n",
    "\n",
    "        # Pick the normalized form corresponding to the training phase.\n",
    "        return K.in_train_phase(input_bn, normalize_inference, training = training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'axis': self.axis,\n",
    "            'momentum': self.momentum,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer':              sanitizedInitSer(self.beta_initializer),\n",
    "            'gamma_diag_initializer':        sanitizedInitSer(self.gamma_diag_initializer),\n",
    "            'gamma_off_initializer':         sanitizedInitSer(self.gamma_off_initializer),\n",
    "            'moving_mean_initializer':       sanitizedInitSer(self.moving_mean_initializer),\n",
    "            'moving_variance_initializer':   sanitizedInitSer(self.moving_variance_initializer),\n",
    "            'moving_covariance_initializer': sanitizedInitSer(self.moving_covariance_initializer),\n",
    "            'beta_regularizer':              regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_diag_regularizer':        regularizers.serialize(self.gamma_diag_regularizer),\n",
    "            'gamma_off_regularizer':         regularizers.serialize(self.gamma_off_regularizer),\n",
    "            'beta_constraint':               constraints .serialize(self.beta_constraint),\n",
    "            'gamma_diag_constraint':         constraints .serialize(self.gamma_diag_constraint),\n",
    "            'gamma_off_constraint':          constraints .serialize(self.gamma_off_constraint),}\n",
    "        base_config = super(complex_BatchNorm2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE complex_BatchNorm1D\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "class complex_BatchNorm1D (tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                axis = -1,\n",
    "                momentum = 0.9,\n",
    "                epsilon = 1e-4,\n",
    "                center = True,\n",
    "                scale = True,\n",
    "                beta_initializer = 'zeros',\n",
    "                gamma_diag_initializer = 'sqrt_init',\n",
    "                gamma_off_initializer = 'zeros',\n",
    "                moving_mean_initializer = 'zeros',\n",
    "                moving_variance_initializer = 'sqrt_init',\n",
    "                moving_covariance_initializer = 'zeros',\n",
    "                beta_regularizer = None,\n",
    "                gamma_diag_regularizer = None,\n",
    "                gamma_off_regularizer = None,\n",
    "                beta_constraint = None,\n",
    "                gamma_diag_constraint = None,\n",
    "                gamma_off_constraint = None,\n",
    "                **kwargs):\n",
    "\n",
    "        super(complex_BatchNorm1D, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking              = True\n",
    "        self.axis                          = axis\n",
    "        self.momentum                      = momentum\n",
    "        self.epsilon                       = epsilon\n",
    "        self.center                        = center\n",
    "        self.scale                         = scale\n",
    "        self.beta_initializer              = sanitizedInitGet(beta_initializer)\n",
    "        self.gamma_diag_initializer        = sanitizedInitGet(gamma_diag_initializer)\n",
    "        self.gamma_off_initializer         = sanitizedInitGet(gamma_off_initializer)\n",
    "        self.moving_mean_initializer       = sanitizedInitGet(moving_mean_initializer)\n",
    "        self.moving_variance_initializer   = sanitizedInitGet(moving_variance_initializer)\n",
    "        self.moving_covariance_initializer = sanitizedInitGet(moving_covariance_initializer)\n",
    "        self.beta_regularizer              = regularizers.get(beta_regularizer)\n",
    "        self.gamma_diag_regularizer        = regularizers.get(gamma_diag_regularizer)\n",
    "        self.gamma_off_regularizer         = regularizers.get(gamma_off_regularizer)\n",
    "        self.beta_constraint               = constraints .get(beta_constraint)\n",
    "        self.gamma_diag_constraint         = constraints .get(gamma_diag_constraint)\n",
    "        self.gamma_off_constraint          = constraints .get(gamma_off_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        ndim = len(input_shape)        # 3\n",
    "        dim = input_shape[self.axis]        # [ :, :, dim]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of ' 'input tensor should have a defined dimension ' 'but the layer received an input with shape ' + str(input_shape) + '.')\n",
    "        \n",
    "        self.input_spec = InputSpec(ndim=len(input_shape), axes={self.axis: dim})\n",
    "        param_shape = (input_shape[self.axis] // 2,)        # Respectively, dim of real == 4, dim of imag == 4\n",
    "\n",
    "        if self.scale:        # Additional parameter\n",
    "            self.gamma_rr   = self.add_weight(shape=param_shape, name='gamma_rr', initializer=self.gamma_diag_initializer, regularizer=self.gamma_diag_regularizer, constraint=self.gamma_diag_constraint)\n",
    "            self.gamma_ii   = self.add_weight(shape=param_shape, name='gamma_ii', initializer=self.gamma_diag_initializer, regularizer=self.gamma_diag_regularizer, constraint=self.gamma_diag_constraint)\n",
    "            self.gamma_ri   = self.add_weight(shape=param_shape, name='gamma_ri', initializer=self.gamma_off_initializer, regularizer=self.gamma_off_regularizer, constraint=self.gamma_off_constraint)\n",
    "            self.moving_Vrr = self.add_weight(shape=param_shape, initializer=self.moving_variance_initializer, name='moving_Vrr', trainable=False)\n",
    "            self.moving_Vii = self.add_weight(shape=param_shape, initializer=self.moving_variance_initializer, name='moving_Vii', trainable=False)\n",
    "            self.moving_Vri = self.add_weight(shape=param_shape, initializer=self.moving_covariance_initializer, name='moving_Vri', trainable=False)\n",
    "        else:\n",
    "            self.gamma_rr   = None\n",
    "            self.gamma_ii   = None\n",
    "            self.gamma_ri   = None\n",
    "            self.moving_Vrr = None\n",
    "            self.moving_Vii = None\n",
    "            self.moving_Vri = None\n",
    "\n",
    "        if self.center:\n",
    "            self.beta        = self.add_weight(shape=(input_shape[self.axis],), name='beta', initializer=self.beta_initializer, regularizer=self.beta_regularizer, constraint=self.beta_constraint)\n",
    "            self.moving_mean = self.add_weight(shape=(input_shape[self.axis],), initializer=self.moving_mean_initializer, name='moving_mean', trainable=False)\n",
    "        else:\n",
    "            self.beta        = None\n",
    "            self.moving_mean = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training = None):\n",
    "\n",
    "        input_shape = K.int_shape(inputs) # .shape\n",
    "        ndim        = len(input_shape) # 4\n",
    "\n",
    "        reduction_axes = list(range(ndim)) # If ndim == 4, list(range(ndim)) == [0, 1, 2, 3]\n",
    "        del reduction_axes[self.axis] # --> [0, 1, 2], self.axis == -1\n",
    "\n",
    "        input_dim = input_shape[self.axis] // 2\n",
    "        mu        = K.mean(inputs, axis = reduction_axes) # real mu, imag mu\n",
    "\n",
    "        broadcast_mu_shape            = [1] * len(input_shape) # [1, 1, 1, 1]\n",
    "        broadcast_mu_shape[self.axis] = input_shape[self.axis] # [1, 1, 1, input_shape[self.axis]]\n",
    "        broadcast_mu                  = K.reshape(mu, broadcast_mu_shape) # mu shape is [1, 1, 1, 2]\n",
    "\n",
    "        \"\"\"\n",
    "        real parts에는 real mean을 빼고\n",
    "        imag parts에는 imag mean을 뺀다\n",
    "        centred_squared == (x - E(x))^2\n",
    "        \"\"\"\n",
    "        if self.center:\n",
    "            input_centred = inputs - broadcast_mu\n",
    "        else:\n",
    "            input_centred = inputs\n",
    "\n",
    "        centred_squared = input_centred ** 2\n",
    "\n",
    "        'for Conv2D'\n",
    "        centred_squared_real = centred_squared[:, :, :input_dim] # real\n",
    "        centred_squared_imag = centred_squared[:, :, input_dim:] # imag\n",
    "        centred_real = input_centred[:, :, :input_dim] # real\n",
    "        centred_imag = input_centred[:, :, input_dim:] # imag\n",
    "\n",
    "        if self.scale:\n",
    "            Vrr = K.mean(centred_squared_real, axis=reduction_axes) + self.epsilon\n",
    "            Vii = K.mean(centred_squared_imag, axis=reduction_axes) + self.epsilon\n",
    "            Vri = K.mean(centred_real * centred_imag, axis=reduction_axes,) # Vri contains the real and imaginary covariance for each feature map.\n",
    "        elif self.center:\n",
    "            Vrr = None\n",
    "            Vii = None\n",
    "            Vri = None\n",
    "        else:\n",
    "            raise ValueError('Error. Both scale and center in batchnorm are set to False.')\n",
    "\n",
    "        \"\"\"\n",
    "        1. Calcultae BatchNormalization for real parts, imag parts of complex numbers\n",
    "        2. If Training == True, Under self.center and self.scale condition, Update parameter moving mean, moving_Vrr, moving_Vii, moving_Vri\n",
    "        \"\"\"\n",
    "        input_bn = complex_batchnorm(input_centred, Vrr, Vii, Vri, self.beta, self.gamma_rr, self.gamma_ri, self.gamma_ii, self.scale, self.center, axis = self.axis)\n",
    "\n",
    "        if training in {0, False}:\n",
    "            return input_bn\n",
    "        else: # traning is True!!!\n",
    "            update_list = []\n",
    "            if self.center:\n",
    "                update_list.append(K.moving_average_update(self.moving_mean, mu, self.momentum))\n",
    "            if self.scale:\n",
    "                update_list.append(K.moving_average_update(self.moving_Vrr, Vrr, self.momentum))\n",
    "                update_list.append(K.moving_average_update(self.moving_Vii, Vii, self.momentum))\n",
    "                update_list.append(K.moving_average_update(self.moving_Vri, Vri, self.momentum))\n",
    "            self.add_update(update_list, inputs)\n",
    "\n",
    "            def normalize_inference():\n",
    "                if self.center:\n",
    "                    inference_centred = inputs - K.reshape(self.moving_mean, broadcast_mu_shape)\n",
    "                else:\n",
    "                    inference_centred = inputs\n",
    "                return complex_batchnorm(inference_centred, \n",
    "                                self.moving_Vrr, self.moving_Vii, self.moving_Vri, self.beta, \n",
    "                                self.gamma_rr, self.gamma_ri, self.gamma_ii, self.scale, self.center, axis = self.axis)\n",
    "\n",
    "        # Pick the normalized form corresponding to the training phase.\n",
    "        return K.in_train_phase(input_bn, normalize_inference, training = training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'axis': self.axis,\n",
    "            'momentum': self.momentum,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer':              sanitizedInitSer(self.beta_initializer),\n",
    "            'gamma_diag_initializer':        sanitizedInitSer(self.gamma_diag_initializer),\n",
    "            'gamma_off_initializer':         sanitizedInitSer(self.gamma_off_initializer),\n",
    "            'moving_mean_initializer':       sanitizedInitSer(self.moving_mean_initializer),\n",
    "            'moving_variance_initializer':   sanitizedInitSer(self.moving_variance_initializer),\n",
    "            'moving_covariance_initializer': sanitizedInitSer(self.moving_covariance_initializer),\n",
    "            'beta_regularizer':              regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_diag_regularizer':        regularizers.serialize(self.gamma_diag_regularizer),\n",
    "            'gamma_off_regularizer':         regularizers.serialize(self.gamma_off_regularizer),\n",
    "            'beta_constraint':               constraints .serialize(self.beta_constraint),\n",
    "            'gamma_diag_constraint':         constraints .serialize(self.gamma_diag_constraint),\n",
    "            'gamma_off_constraint':          constraints .serialize(self.gamma_off_constraint),}\n",
    "        base_config = super(complex_BatchNorm2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "DEFINE complex_BatchNorm2D\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "class complex_BatchNorm2D (tf.keras.layers.Layer):\n",
    "    \"\"\"Complex version of the real domain\n",
    "    Batch normalization layer (Ioffe and Szegedy, 2014).\n",
    "    Normalize the activations of the previous complex layer at each batch,\n",
    "    i.e. applies a transformation that maintains the mean of a complex unit\n",
    "    close to the null vector, the 2 by 2 covariance matrix of a complex unit close to identity\n",
    "    and the 2 by 2 relation matrix, also called pseudo-covariance, close to the\n",
    "    null matrix.\n",
    "    # Arguments\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=2` in `complex_BatchNorm2D`.\n",
    "        momentum: Momentum for the moving statistics related to the real and\n",
    "            imaginary parts.\n",
    "        epsilon: Small float added to each of the variances related to the\n",
    "            real and imaginary parts in order to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to complex normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "            (beta is formed by real_beta and imag_beta)\n",
    "        scale: If True, multiply by the `gamma` matrix.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the real_beta and the imag_beta weight.\n",
    "        gamma_diag_initializer: Initializer for the diagonal elements of the gamma matrix.\n",
    "            which are the variances of the real part and the imaginary part.\n",
    "        gamma_off_initializer: Initializer for the off-diagonal elements of the gamma matrix.\n",
    "        moving_mean_initializer: Initializer for the moving means.\n",
    "        moving_variance_initializer: Initializer for the moving variances.\n",
    "        moving_covariance_initializer: Initializer for the moving covariance of\n",
    "            the real and imaginary parts.\n",
    "        beta_regularizer: Optional regularizer for the beta weights.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weights.\n",
    "        beta_constraint: Optional constraint for the beta weights.\n",
    "        gamma_constraint: Optional constraint for the gamma weights.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 axis = -1,\n",
    "                 momentum = 0.9,\n",
    "                 epsilon = 1e-4,\n",
    "                 center = True,\n",
    "                 scale = True,\n",
    "                 beta_initializer = 'zeros',\n",
    "                 gamma_diag_initializer = 'sqrt_init',\n",
    "                 gamma_off_initializer = 'zeros',\n",
    "                 moving_mean_initializer = 'zeros',\n",
    "                 moving_variance_initializer = 'sqrt_init',\n",
    "                 moving_covariance_initializer = 'zeros',\n",
    "                 beta_regularizer = None,\n",
    "                 gamma_diag_regularizer = None,\n",
    "                 gamma_off_regularizer = None,\n",
    "                 beta_constraint = None,\n",
    "                 gamma_diag_constraint = None,\n",
    "                 gamma_off_constraint = None,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(complex_BatchNorm2D, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis             = axis\n",
    "        self.momentum         = momentum\n",
    "        self.epsilon          = epsilon\n",
    "        self.center           = center\n",
    "        self.scale            = scale\n",
    "        self.beta_initializer              = sanitizedInitGet(beta_initializer)\n",
    "        self.gamma_diag_initializer        = sanitizedInitGet(gamma_diag_initializer)\n",
    "        self.gamma_off_initializer         = sanitizedInitGet(gamma_off_initializer)\n",
    "        self.moving_mean_initializer       = sanitizedInitGet(moving_mean_initializer)\n",
    "        self.moving_variance_initializer   = sanitizedInitGet(moving_variance_initializer)\n",
    "        self.moving_covariance_initializer = sanitizedInitGet(moving_covariance_initializer)\n",
    "        self.beta_regularizer              = regularizers.get(beta_regularizer)\n",
    "        self.gamma_diag_regularizer        = regularizers.get(gamma_diag_regularizer)\n",
    "        self.gamma_off_regularizer         = regularizers.get(gamma_off_regularizer)\n",
    "        self.beta_constraint               = constraints .get(beta_constraint)\n",
    "        self.gamma_diag_constraint         = constraints .get(gamma_diag_constraint)\n",
    "        self.gamma_off_constraint          = constraints .get(gamma_off_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # 4\n",
    "        ndim = len(input_shape)\n",
    "\n",
    "        # [ :, :, :, dim]\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of ' 'input tensor should have a defined dimension ' 'but the layer received an input with shape ' + str(input_shape) + '.')\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape), axes={self.axis: dim})\n",
    "\n",
    "        # Respectively, real == 4, imag == 4\n",
    "        param_shape = (input_shape[self.axis] // 2,)\n",
    "\n",
    "        # Additional parameter\n",
    "        if self.scale:\n",
    "            self.gamma_rr   = self.add_weight(shape=param_shape, name='gamma_rr', initializer=self.gamma_diag_initializer, regularizer=self.gamma_diag_regularizer, constraint=self.gamma_diag_constraint)\n",
    "            self.gamma_ii   = self.add_weight(shape=param_shape, name='gamma_ii', initializer=self.gamma_diag_initializer, regularizer=self.gamma_diag_regularizer, constraint=self.gamma_diag_constraint)\n",
    "            self.gamma_ri   = self.add_weight(shape=param_shape, name='gamma_ri', initializer=self.gamma_off_initializer, regularizer=self.gamma_off_regularizer, constraint=self.gamma_off_constraint)\n",
    "            self.moving_Vrr = self.add_weight(shape=param_shape, initializer=self.moving_variance_initializer, name='moving_Vrr', trainable=False)\n",
    "            self.moving_Vii = self.add_weight(shape=param_shape, initializer=self.moving_variance_initializer, name='moving_Vii', trainable=False)\n",
    "            self.moving_Vri = self.add_weight(shape=param_shape, initializer=self.moving_covariance_initializer, name='moving_Vri', trainable=False)\n",
    "        else:\n",
    "            self.gamma_rr   = None\n",
    "            self.gamma_ii   = None\n",
    "            self.gamma_ri   = None\n",
    "            self.moving_Vrr = None\n",
    "            self.moving_Vii = None\n",
    "            self.moving_Vri = None\n",
    "\n",
    "        if self.center:\n",
    "            self.beta        = self.add_weight(shape=(input_shape[self.axis],), name='beta', initializer=self.beta_initializer, regularizer=self.beta_regularizer, constraint=self.beta_constraint)\n",
    "            self.moving_mean = self.add_weight(shape=(input_shape[self.axis],), initializer=self.moving_mean_initializer, name='moving_mean', trainable=False)\n",
    "        else:\n",
    "            self.beta        = None\n",
    "            self.moving_mean = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = None):\n",
    "\n",
    "        input_shape = K.int_shape(inputs) # .shape\n",
    "        ndim        = len(input_shape) # 4\n",
    "\n",
    "        reduction_axes = list(range(ndim)) # If ndim == 4, list(range(ndim)) == [0, 1, 2, 3]\n",
    "        del reduction_axes[self.axis] # --> [0, 1, 2], self.axis == -1\n",
    "\n",
    "        input_dim = input_shape[self.axis] // 2\n",
    "\n",
    "        mu = K.mean(inputs, axis = reduction_axes) # real mu, imag mu\n",
    "\n",
    "        broadcast_mu_shape            = [1] * len(input_shape) # [1, 1, 1, 1]\n",
    "        broadcast_mu_shape[self.axis] = input_shape[self.axis] # [1, 1, 1, input_shape[self.axis]]\n",
    "        broadcast_mu                  = K.reshape(mu, broadcast_mu_shape) # mu shape is [1, 1, 1, 2]\n",
    "\n",
    "        \"\"\"\n",
    "        real parts에는 real mean을 빼고\n",
    "        imag parts에는 imag mean을 뺀다\n",
    "        centred_squared == (x - E(x))^2\n",
    "        \"\"\"\n",
    "        if self.center:\n",
    "            input_centred = inputs - broadcast_mu\n",
    "        else:\n",
    "            input_centred = inputs\n",
    "\n",
    "        centred_squared = input_centred ** 2\n",
    "\n",
    "        'for Conv2D'\n",
    "        centred_squared_real = centred_squared[:, :, :, :input_dim] # real\n",
    "        centred_squared_imag = centred_squared[:, :, :, input_dim:] # imag\n",
    "        centred_real = input_centred[:, :, :, :input_dim] # real\n",
    "        centred_imag = input_centred[:, :, :, input_dim:] # imag\n",
    "\n",
    "        if self.scale:\n",
    "            Vrr = K.mean(centred_squared_real, axis=reduction_axes) + self.epsilon\n",
    "            Vii = K.mean(centred_squared_imag, axis=reduction_axes) + self.epsilon\n",
    "            Vri = K.mean(centred_real * centred_imag, axis=reduction_axes,) # Vri contains the real and imaginary covariance for each feature map.\n",
    "        elif self.center:\n",
    "            Vrr = None\n",
    "            Vii = None\n",
    "            Vri = None\n",
    "        else:\n",
    "            raise ValueError('Error. Both scale and center in batchnorm are set to False.')\n",
    "\n",
    "        \"\"\"\n",
    "        1. Calcultae BatchNormalization for real parts, imag parts of complex numbers\n",
    "        2. If Training == True, Under self.center and self.scale condition, Update parameter moving mean, moving_Vrr, moving_Vii, moving_Vri\n",
    "        \"\"\"\n",
    "        input_bn = complex_batchnorm(input_centred, Vrr, Vii, Vri, self.beta, self.gamma_rr, self.gamma_ri, self.gamma_ii, self.scale, self.center, axis = self.axis)\n",
    "\n",
    "        if training in {0, False}:\n",
    "            return input_bn\n",
    "        else: # traning is True!!!\n",
    "            update_list = []\n",
    "            if self.center:\n",
    "                update_list.append(K.moving_average_update(self.moving_mean, mu, self.momentum))\n",
    "            if self.scale:\n",
    "                update_list.append(K.moving_average_update(self.moving_Vrr, Vrr, self.momentum))\n",
    "                update_list.append(K.moving_average_update(self.moving_Vii, Vii, self.momentum))\n",
    "                update_list.append(K.moving_average_update(self.moving_Vri, Vri, self.momentum))\n",
    "            self.add_update(update_list, inputs)\n",
    "\n",
    "            def normalize_inference():\n",
    "                if self.center:\n",
    "                    inference_centred = inputs - K.reshape(self.moving_mean, broadcast_mu_shape)\n",
    "                else:\n",
    "                    inference_centred = inputs\n",
    "                return complex_batchnorm(inference_centred, \n",
    "                                self.moving_Vrr, self.moving_Vii, self.moving_Vri, self.beta, \n",
    "                                self.gamma_rr, self.gamma_ri, self.gamma_ii, self.scale, self.center, axis = self.axis)\n",
    "\n",
    "        # Pick the normalized form corresponding to the training phase.\n",
    "        return K.in_train_phase(input_bn, normalize_inference, training = training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'axis': self.axis,\n",
    "            'momentum': self.momentum,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer':              sanitizedInitSer(self.beta_initializer),\n",
    "            'gamma_diag_initializer':        sanitizedInitSer(self.gamma_diag_initializer),\n",
    "            'gamma_off_initializer':         sanitizedInitSer(self.gamma_off_initializer),\n",
    "            'moving_mean_initializer':       sanitizedInitSer(self.moving_mean_initializer),\n",
    "            'moving_variance_initializer':   sanitizedInitSer(self.moving_variance_initializer),\n",
    "            'moving_covariance_initializer': sanitizedInitSer(self.moving_covariance_initializer),\n",
    "            'beta_regularizer':              regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_diag_regularizer':        regularizers.serialize(self.gamma_diag_regularizer),\n",
    "            'gamma_off_regularizer':         regularizers.serialize(self.gamma_off_regularizer),\n",
    "            'beta_constraint':               constraints .serialize(self.beta_constraint),\n",
    "            'gamma_diag_constraint':         constraints .serialize(self.gamma_diag_constraint),\n",
    "            'gamma_off_constraint':          constraints .serialize(self.gamma_off_constraint),}\n",
    "        base_config = super(complex_BatchNorm2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def complex_BatchNormalization (real, imag, training = None):\n",
    "    inputs = tf.concat([real, imag], axis = -1)\n",
    "    outputs = complex_Dense_BatchNorm()(inputs, training = training)\n",
    "\n",
    "    input_dim = outputs.shape[-1] // 2\n",
    "    real = outputs[ :, :input_dim]\n",
    "    imag = outputs[ :, input_dim:]\n",
    "    return real, imag\n",
    "\n",
    "\n",
    "def complex_BatchNormalization1D (real, imag, training = None):\n",
    "    inputs = tf.concat([real, imag], axis = -1)\n",
    "    outputs = complex_BatchNorm1D()(inputs, training = training)\n",
    "\n",
    "    input_dim = outputs.shape[-1] // 2\n",
    "    real = outputs[ :, :, :input_dim]\n",
    "    imag = outputs[ :, :, input_dim:]\n",
    "    return real, imag\n",
    "\n",
    "\n",
    "def complex_BatchNormalization2D (real, imag, training = None):\n",
    "    inputs = tf.concat([real, imag], axis = -1)\n",
    "    outputs = complex_BatchNorm2D()(inputs, training = training)\n",
    "\n",
    "    input_dim = outputs.shape[-1] // 2\n",
    "    real = outputs[ :, :, :, :input_dim]\n",
    "    imag = outputs[ :, :, :, input_dim:]\n",
    "    return real, imag\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
