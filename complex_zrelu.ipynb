{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b0c795-5c29-4297-9efb-00c6002ec6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Add, LeakyReLU,  \\\n",
    "                                    MaxPooling2D, concatenate, UpSampling2D, Multiply, ZeroPadding2D, Cropping2D\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf373c64-693b-48cc-a691-7558ed602225",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'./Modules/layer.ipynb'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\IPython\\core\\magics\\execution.py:716\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    715\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 716\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\IPython\\utils\\path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[1;31mOSError\u001b[0m: File `'./Modules/layer.ipynb'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Modules/layer.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Modules/activation.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\IPython\\core\\magics\\execution.py:727\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[0;32m    726\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[1;31mException\u001b[0m: File `'./Modules/layer.ipynb'` not found."
     ]
    }
   ],
   "source": [
    "%run ./Modules/layer.ipynb\n",
    "%run ./Modules/activation.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea833c9e-ccde-4cce-984c-406c3b53ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "\n",
    "def fft_layer(image):\n",
    "    # get real and imaginary portions\n",
    "    real = Lambda(lambda image: image[:, :, :, 0])(image)\n",
    "    imag = Lambda(lambda image: image[:, :, :, 1])(image)\n",
    "\n",
    "    image_complex = tf.complex(real, imag)  # Make complex-valued tensor\n",
    "    kspace_complex = tf.signal.fft2d(image_complex)\n",
    "\n",
    "    # expand channels to tensorflow/keras format\n",
    "    real = tf.expand_dims(tf.math.real(kspace_complex), -1)\n",
    "    imag = tf.expand_dims(tf.math.imag(kspace_complex), -1)\n",
    "    kspace = tf.concat([real, imag], -1)\n",
    "    return kspace\n",
    "\n",
    "def fft_layer2(real,imag):\n",
    "    # get real and imaginary portions\n",
    "    image_complex = tf.complex(real, imag)  # Make complex-valued tensor\n",
    "    kspace_complex = tf.signal.fft2d(image_complex)\n",
    "\n",
    "    # expand channels to tensorflow/keras format\n",
    "    real = tf.math.real(kspace_complex)\n",
    "    imag = tf.math.imag(kspace_complex)\n",
    "    \n",
    "    return real,imag\n",
    "\n",
    "\n",
    "def ifft_layer(kspace_2channel):\n",
    "    #get real and imaginary portions\n",
    "    real = Lambda(lambda kspace_2channel : kspace_2channel[:,:,:,0])(kspace_2channel)\n",
    "    imag = Lambda(lambda kspace_2channel : kspace_2channel[:,:,:,1])(kspace_2channel)\n",
    "\n",
    "    kspace_complex = tf.complex(real,imag) # Make complex-valued tensor\n",
    "    image_complex = tf.signal.ifft2d(kspace_complex)\n",
    "\n",
    "    # expand channels to tensorflow/keras format\n",
    "    real = tf.expand_dims(tf.math.real(image_complex),-1)\n",
    "    imag = tf.expand_dims(tf.math.imag(image_complex),-1)\n",
    "    # generate 2-channel representation of image domain\n",
    "    image_complex_2channel = tf.concat([real, imag], -1)\n",
    "    return image_complex_2channel\n",
    "def ifft_layer2(real,imag):\n",
    "    #get real and imaginary portions\n",
    "    kspace_complex = tf.complex(real,imag) # Make complex-valued tensor\n",
    "    image_complex = tf.signal.ifft2d(kspace_complex)\n",
    "\n",
    "    # expand channels to tensorflow/keras format\n",
    "    real = tf.math.real(image_complex)\n",
    "    imag = tf.math.imag(image_complex)\n",
    "    # generate 2-channel representation of image domain\n",
    "    \n",
    "    return real,imag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d698c-b69d-4c76-aedf-c70bf6800c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DC_block(rec,mask,sampled_kspace,channels,kspace = False):\n",
    "    \"\"\"\n",
    "    :param rec: Reconstructed data, can be k-space or image domain\n",
    "    :param mask: undersampling mask\n",
    "    :param sampled_kspace:\n",
    "    :param kspace: Boolean, if true, the input is k-space, if false it is image domain\n",
    "    :return: k-space after data consistency\n",
    "    \"\"\"\n",
    "\n",
    "    if kspace:\n",
    "        rec_kspace = rec\n",
    "    else:\n",
    "        rec_kspace = Lambda(fft_layer)(rec)\n",
    "    mask = 1 - mask\n",
    "    rec_kspace_dc =  Multiply()([rec_kspace,mask])\n",
    "    rec_kspace_dc = Add()([rec_kspace_dc,sampled_kspace])\n",
    "    return rec_kspace_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b0fe7-f854-4541-b1bc-fb5870596225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Conv2D, Activation, Multiply\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def spatial_attention_complex(real, imag):\n",
    "    \"\"\"\n",
    "    Applies spatial attention to complex feature maps.\n",
    "    Attention is applied equally to both real and imaginary parts.\n",
    "\n",
    "    :param real: Real part of feature map, shape [B, H, W, C]\n",
    "    :param imag: Imaginary part of feature map, shape [B, H, W, C]\n",
    "    :return: real_out, imag_out with spatial attention applied\n",
    "    \"\"\"\n",
    "    # Combine real and imag via concatenation or magnitude\n",
    "    combined = K.sqrt(K.square(real) + K.square(imag))  # shape [B, H, W, C]\n",
    "    \n",
    "    # Compute spatial attention (mean over channels)\n",
    "    avg_pool = K.mean(combined, axis=-1, keepdims=True)  # [B, H, W, 1]\n",
    "    max_pool = K.max(combined, axis=-1, keepdims=True)   # [B, H, W, 1]\n",
    "    \n",
    "    concat = Concatenate(axis=-1)([avg_pool, max_pool])  # [B, H, W, 2]\n",
    "    \n",
    "    # 7x7 convolution for spatial attention\n",
    "    attention_map = Conv2D(filters=1, kernel_size=7, padding='same', activation='sigmoid')(concat)  # [B, H, W, 1]\n",
    "    \n",
    "    # Apply attention map to both real and imag\n",
    "    real_out = Multiply()([real, attention_map])\n",
    "    imag_out = Multiply()([imag, attention_map])\n",
    "    \n",
    "    return real_out, imag_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5c7bc-67e3-4f2a-96e5-b58881888d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, LeakyReLU, Add\n",
    "from keras import backend as K\n",
    "def cnn_block(cnn_input, nf, kshape, channels):\n",
    "    \"\"\"\n",
    "    CNN block with fixed depth of 5.\n",
    "    Applies 5 convolutional layers followed by a final 1x1 convolution.\n",
    "    \n",
    "    :param cnn_input: Input layer to CNN block\n",
    "    :param nf: Number of filters in convolutional layers\n",
    "    :param kshape: Shape of the convolutional kernel\n",
    "    :param channels: Number of output channels (2 for real and imaginary)\n",
    "    :return: 2-channel complex reconstruction with residual connection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate real and imaginary parts\n",
    "    real = cnn_input[..., 0]  # First channel (real part)\n",
    "    imag = cnn_input[..., 1]  # Second channel (imaginary part)\n",
    "    #print(\"real\",real.shape)\n",
    "    #print(\"imag\",imag.shape)\n",
    "    real = K.expand_dims(real, axis=-1)  # Shape becomes (None, 256, 256, 1)\n",
    "    imag = K.expand_dims(imag, axis=-1)  # Shape becomes (None, 256, 256, 1)\n",
    "    # Print the new shapes\n",
    "    #print(\"real after\", real.shape)  # Should print (None, 256, 256, 1)\n",
    "    #print(\"imag after\", imag.shape)\n",
    "\n",
    "\n",
    "    # First convolution and activation\n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real,imag)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    real_conv1, imag_conv1  = complex_Conv2D(nf, kshape, padding='same')(real_conv1, imag_conv1 )\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real_conv1,imag_conv1)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real_conv1,imag_conv1)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real_conv1,imag_conv1)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "    real_conv1, imag_conv1=spatial_attention_complex(real_conv1, imag_conv1)\n",
    "    \n",
    "\n",
    "    # Final 1x1 convolution to return to 2 channels\n",
    "    real_fianl, imag_final = complex_Conv2D(2, (1, 1))(real_conv1, imag_conv1 )\n",
    "    #print(\"in image domain:real_fianl\",real_fianl.shape)\n",
    "\n",
    "    # Add residual connection (input + CNN output)\n",
    "    real_res1,imag_res1=add_with(real_fianl, imag_final,real,imag)\n",
    "    res1 =concatenate([real_res1,imag_res1],axis=-1)\n",
    "    \n",
    "    return res1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9dae7-de54-4c40-a620-dd955cba222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, LeakyReLU, Add\n",
    "from keras import backend as K\n",
    "def cnn_block_kspace(cnn_input,nf, kshape, channels):\n",
    "    \"\"\"\n",
    "    CNN block with fixed depth of 5.\n",
    "    Applies 5 convolutional layers followed by a final 1x1 convolution.\n",
    "    \n",
    "    :param cnn_input: Input layer to CNN block\n",
    "    :param nf: Number of filters in convolutional layers\n",
    "    :param kshape: Shape of the convolutional kernel\n",
    "    :param channels: Number of output channels (2 for real and imaginary)\n",
    "    :return: 2-channel complex reconstruction with residual connection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate real and imaginary parts\n",
    "    real = cnn_input[..., 0]  # First channel (real part)\n",
    "    imag = cnn_input[..., 1]  # Second channel (imaginary part)\n",
    "    #print(\"real\",real.shape)\n",
    "    #print(\"imag\",imag.shape)\n",
    "    real = K.expand_dims(real, axis=-1)  # Shape becomes (None, 256, 256, 1)\n",
    "    imag = K.expand_dims(imag, axis=-1)  # Shape becomes (None, 256, 256, 1)\n",
    "    # Print the new shapes\n",
    "    #print(\"real after\", real.shape)  # Should print (None, 256, 256, 1)\n",
    "    #print(\"imag after\", imag.shape)\n",
    "\n",
    "\n",
    "    # First convolution and activation\n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real,imag)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    real_conv1, imag_conv1  = complex_Conv2D(nf, kshape, padding='same')(real_conv1, imag_conv1 )\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real_conv1,imag_conv1)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real_conv1,imag_conv1)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "    real_conv1, imag_conv1 = complex_Conv2D(nf, kshape,  padding=\"same\")(real_conv1,imag_conv1)\n",
    "    real_conv1, imag_conv1 =CLeaky_ReLU(real_conv1, imag_conv1)\n",
    "    real_conv1, imag_conv1=ifft_layer2( real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "    real_conv1, imag_conv1=spatial_attention_complex(real_conv1, imag_conv1)\n",
    "    #print(\"real_conv1\",real_conv1.shape,\"imag_conv1\",imag_conv1.shape)\n",
    "    real_conv1, imag_conv1=fft_layer2(real_conv1, imag_conv1)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Final 1x1 convolution to return to 2 channels\n",
    "    \n",
    "    real_fianl, imag_final = complex_Conv2D(2, (1, 1))(real_conv1, imag_conv1 )\n",
    "\n",
    "    # Add residual connection (input + CNN output)\n",
    "    #print(\"real_fianl\",real_fianl.shape,\"imag_final\",imag_final.shape)\n",
    "    real_res1,imag_res1=add_with(real_fianl, imag_final,real,imag)\n",
    "    res1 =concatenate([real_res1,imag_res1],axis=-1)\n",
    "    \n",
    "    return res1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0105c3-ee92-4780-a676-e7b856e97969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_cascade_flat_unrolled(depth_str='ikikii', H=256, W=256, kshape=(3, 3), nf=48, channels=2):\n",
    "    \"\"\"\n",
    "    Deep Cascade Flat Unrolled model with different CNNs for k-space and image-space.\n",
    "    \n",
    "    :param depth_str: String defining the sequence of IFFT ('i') and CNN in k-space ('k')\n",
    "    :param H: Image height\n",
    "    :param W: Image width\n",
    "    :param kshape: Kernel size for CNN\n",
    "    :param nf: Number of filters in CNN\n",
    "    :param channels: Number of input/output channels (real + imaginary = 2)\n",
    "    :return: Keras model\n",
    "    \"\"\"\n",
    "\n",
    "    from keras.layers import Input, Lambda\n",
    "    from keras.models import Model\n",
    "\n",
    "    inputs = Input(shape=(H, W, channels))  # Input k-space data\n",
    "    mask = Input(shape=(H, W, channels))    # Undersampling mask\n",
    "\n",
    "    x = inputs\n",
    "    kspace_flag = True  # Tracks if we are currently in k-space\n",
    "\n",
    "    for ii in depth_str:\n",
    "        if ii == 'i':\n",
    "            x = Lambda(ifft_layer)(x)\n",
    "            kspace_flag = False\n",
    "            x = cnn_block(x, nf, kshape, channels)  # CNN in image domain\n",
    "\n",
    "        elif ii == 'k':\n",
    "            # If needed, can wrap with FFT here too\n",
    "            # x = Lambda(fft_layer)(x) if not in k-space already\n",
    "            kspace_flag = True\n",
    "            x = cnn_block_kspace(x, nf, kshape, channels)  # CNN in k-space\n",
    "\n",
    "        # Apply DC block after every CNN\n",
    "        x = DC_block(x, mask, inputs, channels, kspace=kspace_flag)\n",
    "\n",
    "    out = Lambda(ifft_layer)(x)  # Final IFFT to return to image domain\n",
    "    model = Model(inputs=[inputs, mask], outputs=out)\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
