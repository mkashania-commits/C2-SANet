{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d95001-ca8b-4c89-98ee-6b67947f67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Add, LeakyReLU,  \\\n",
    "                                    MaxPooling2D, concatenate, UpSampling2D,\\\n",
    "                                    Multiply, ZeroPadding2D, Cropping2D,Activation\n",
    "  \n",
    "\n",
    "def fft_layer(image):\n",
    "    # get real and imaginary portions\n",
    "    real = Lambda(lambda image: image[:, :, :, 0])(image)\n",
    "    imag = Lambda(lambda image: image[:, :, :, 1])(image)\n",
    "\n",
    "    image_complex = tf.complex(real, imag)  # Make complex-valued tensor\n",
    "    kspace_complex = tf.signal.fft2d(image_complex)\n",
    "\n",
    "    # expand channels to tensorflow/keras format\n",
    "    real = tf.expand_dims(tf.math.real(kspace_complex), -1)\n",
    "    imag = tf.expand_dims(tf.math.imag(kspace_complex), -1)\n",
    "    kspace = tf.concat([real, imag], -1)\n",
    "    return kspace\n",
    "\n",
    "\n",
    "def ifft_layer(kspace_2channel):\n",
    "    #get real and imaginary portions\n",
    "    real = Lambda(lambda kspace_2channel : kspace_2channel[:,:,:,0])(kspace_2channel)\n",
    "    imag = Lambda(lambda kspace_2channel : kspace_2channel[:,:,:,1])(kspace_2channel)\n",
    "\n",
    "    kspace_complex = tf.complex(real,imag) # Make complex-valued tensor\n",
    "    image_complex = tf.signal.ifft2d(kspace_complex)\n",
    "\n",
    "    # expand channels to tensorflow/keras format\n",
    "    real = tf.expand_dims(tf.math.real(image_complex),-1)\n",
    "    imag = tf.expand_dims(tf.math.imag(image_complex),-1)\n",
    "    # generate 2-channel representation of image domain\n",
    "    image_complex_2channel = tf.concat([real, imag], -1)\n",
    "    return image_complex_2channel\n",
    "def spatial_attention(input_feature):\n",
    "    avg_pool = tf.reduce_mean(input_feature, axis=-1, keepdims=True)\n",
    "    max_pool = tf.reduce_max(input_feature, axis=-1, keepdims=True)\n",
    "    concat = tf.concat([avg_pool, max_pool], axis=-1)\n",
    "    attention = Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "    return Multiply()([input_feature, attention])\n",
    "\n",
    "def cnn_block(cnn_input, error_map, depth, nf, kshape, channels):\n",
    "    \"\"\"\n",
    "    CNN block with error propagation and spatial attention after the first convolution layer\n",
    "    :param cnn_input: Input layer to CNN block (image or k-space data).\n",
    "    :param error_map: Error map from the previous block (None for the first block).\n",
    "    :param depth: Number of layers for convolutional block.\n",
    "    :param nf: Number of filters in convolution layers.\n",
    "    :param kshape: Shape of the convolutional kernel.\n",
    "    :param channels: Output channels (for the final 2-channel image).\n",
    "    :return: Refined 2-channel reconstruction and the error map for the next block.\n",
    "    \"\"\"\n",
    "    layers = [cnn_input]\n",
    "\n",
    "    # If there is an error map, concatenate it with the input to guide the block\n",
    "    if error_map is not None:\n",
    "        # Concatenate the error map with the input data (channels last)\n",
    "        layers.append(error_map)\n",
    "    \n",
    "    # Add first convolutional layer\n",
    "    layers.append(Conv2D(nf, kshape, padding='same')(layers[-1]))\n",
    "    layers.append(LeakyReLU(alpha=0.1)(layers[-1]))\n",
    "\n",
    "    # Apply spatial attention after the first convolution layer\n",
    "    # Here we apply spatial attention based on both the feature map and error map\n",
    "    if error_map is not None:\n",
    "        #attention_input = Add()([layers[-1], error_map]) # Combine the feature map and error map\n",
    "        layers[-1] = spatial_attention(layers[-1])  # Apply spatial attention to highlight errors\n",
    "\n",
    "    # Add subsequent convolution layers\n",
    "    for ii in range(1, depth):  # We already processed the first layer\n",
    "        layers.append(Conv2D(nf, kshape, padding='same')(layers[-1]))\n",
    "        layers.append(LeakyReLU(alpha=0.1)(layers[-1]))\n",
    "\n",
    "        # Apply spatial attention after specific layers (optional)\n",
    "        if error_map is None:\n",
    "            if ii == 3:\n",
    "                layers[-1] = spatial_attention(layers[-1])\n",
    "\n",
    "    # Final convolution layer to produce the 2-channel output\n",
    "    final_conv = Conv2D(channels, (1, 1), activation='linear')(layers[-1])\n",
    "\n",
    "    # Compute the error map: difference between the final output and ground truth (or input)\n",
    "    rec1 = Add()([final_conv, cnn_input])  # Residual connection\n",
    "    new_error_map = cnn_input - rec1  # Absolute error between prediction and ground truth\n",
    "    \n",
    "    return rec1, new_error_map\n",
    "\n",
    "\n",
    "def unet_block(unet_input, kshape=(3, 3),channels = 2):\n",
    "    \"\"\"\n",
    "    :param unet_input: Input layer\n",
    "    :param kshape: Kernel size\n",
    "    :return: 2-channel, complex reconstruction\n",
    "    \"\"\"\n",
    "\n",
    "    conv1 = Conv2D(48, kshape, activation='relu', padding='same')(unet_input)\n",
    "    conv1 = Conv2D(48, kshape, activation='relu', padding='same')(conv1)\n",
    "    conv1 = Conv2D(48, kshape, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, kshape, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, kshape, activation='relu', padding='same')(conv2)\n",
    "    conv2 = Conv2D(64, kshape, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, kshape, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, kshape, activation='relu', padding='same')(conv3)\n",
    "    conv3 = Conv2D(128, kshape, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, kshape, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, kshape, activation='relu', padding='same')(conv4)\n",
    "    conv4 = Conv2D(256, kshape, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv2D(128, kshape, activation='relu', padding='same')(up1)\n",
    "    conv5 = Conv2D(128, kshape, activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(128, kshape, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv2D(64, kshape, activation='relu', padding='same')(up2)\n",
    "    conv6 = Conv2D(64, kshape, activation='relu', padding='same')(conv6)\n",
    "    conv6 = Conv2D(64, kshape, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up3 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv2D(48, kshape, activation='relu', padding='same')(up3)\n",
    "    conv7 = Conv2D(48, kshape, activation='relu', padding='same')(conv7)\n",
    "    conv7 = Conv2D(48, kshape, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    conv8 = Conv2D(channels, (1, 1), activation='linear')(conv7)\n",
    "    out = Add()([conv8, unet_input])\n",
    "    return out\n",
    "\n",
    "def unet_block2(unet_input, kshape=(3, 3),channels = 2):\n",
    "    \"\"\"\n",
    "    :param unet_input: Input layer\n",
    "    :param kshape: Kernel size\n",
    "    :return: 2-channel, complex reconstruction\n",
    "    \"\"\"\n",
    "\n",
    "    conv1 = Conv2D(48, kshape, activation='relu', padding='same')(unet_input)\n",
    "    conv1 = Conv2D(48, kshape, activation='relu', padding='same')(conv1)\n",
    "    conv1 = Conv2D(48, kshape, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(96, kshape, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(96, kshape, activation='relu', padding='same')(conv2)\n",
    "    conv2 = Conv2D(96, kshape, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(192, kshape, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(192, kshape, activation='relu', padding='same')(conv3)\n",
    "    conv3 = Conv2D(192, kshape, activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = Conv2D(96, kshape, activation='relu', padding='same')(up1)\n",
    "    conv4 = Conv2D(96, kshape, activation='relu', padding='same')(conv4)\n",
    "    conv4 = Conv2D(96, kshape, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = Conv2D(48, kshape, activation='relu', padding='same')(up2)\n",
    "    conv5 = Conv2D(48, kshape, activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(48, kshape, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(channels, (1, 1), activation='linear')(conv5)\n",
    "    out = Add()([conv6, unet_input])\n",
    "    return out\n",
    "\n",
    "def DC_block(rec,mask,sampled_kspace,channels,kspace = False):\n",
    "    \"\"\"\n",
    "    :param rec: Reconstructed data, can be k-space or image domain\n",
    "    :param mask: undersampling mask\n",
    "    :param sampled_kspace:\n",
    "    :param kspace: Boolean, if true, the input is k-space, if false it is image domain\n",
    "    :return: k-space after data consistency\n",
    "    \"\"\"\n",
    "\n",
    "    if kspace:\n",
    "        rec_kspace = rec\n",
    "    else:\n",
    "        rec_kspace = Lambda(fft_layer)(rec)\n",
    "    mask = 1 - mask\n",
    "    rec_kspace_dc =  Multiply()([rec_kspace,mask])\n",
    "    rec_kspace_dc = Add()([rec_kspace_dc,sampled_kspace])\n",
    "    return rec_kspace_dc\n",
    "\n",
    "def deep_cascade_flat_unrolled(depth_str='iiiiii', H=256, W=256, depth=5, kshape=(3, 3), nf=48, channels=2):\n",
    "    \"\"\"\n",
    "    Deep Cascade model that incorporates error propagation and spatial attention.\n",
    "    :param depth_str: A string that determines the depth and domain of each subnetwork (image or k-space)\n",
    "    :param H: Image height\n",
    "    :param W: Image width\n",
    "    :param kshape: Kernel size\n",
    "    :param nf: Number of filters in each convolutional layer\n",
    "    :return: Deep Cascade model\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(H, W, channels))  # Input image (or k-space)\n",
    "    mask = Input(shape=(H, W, channels))    # Undersampling mask\n",
    "    layers = [inputs]\n",
    "    kspace_flag = True  # Start in k-space domain\n",
    "    \n",
    "    error_map = None  # Initialize the error map as None\n",
    "\n",
    "    for ii in depth_str:\n",
    "        if ii == 'i':\n",
    "            # Add IFFT if switching to image domain\n",
    "            layers.append(Lambda(ifft_layer)(layers[-1]))\n",
    "            kspace_flag = False\n",
    "        \n",
    "        # Add CNN block with error propagation and attention\n",
    "        cnn_output, error_map = cnn_block(layers[-1], error_map, depth, nf, kshape, channels)\n",
    "        layers.append(cnn_output)\n",
    "        \n",
    "        # Add DC block (data consistency block)\n",
    "        dc_output = DC_block(layers[-1], mask, inputs, channels, kspace=kspace_flag)\n",
    "        layers.append(dc_output)\n",
    "        \n",
    "        kspace_flag = True  # Switch back to k-space for the next block\n",
    "    \n",
    "    # Final output (transform back to image domain)\n",
    "    out = Lambda(ifft_layer)(layers[-1])\n",
    "    model = Model(inputs=[inputs, mask], outputs=out)\n",
    "    return model\n",
    "\n",
    "\n",
    "def deep_cascade_unet(depth_str='ki', H=218, W=170, Hpad = 3, Wpad = 3, kshape=(3, 3),channels = 22):\n",
    "\n",
    "    inputs = Input(shape=(H,W,channels))\n",
    "    mask = Input(shape=(H,W,channels))\n",
    "    layers = [inputs]\n",
    "    kspace_flag = True\n",
    "    for ii in depth_str:\n",
    "        \n",
    "        if ii =='i':\n",
    "            # Add IFFT\n",
    "            layers.append(Lambda(ifft_layer)(layers[-1]))\n",
    "            kspace_flag = False\n",
    "        # Add CNN block\n",
    "        layers.append(ZeroPadding2D(padding=(Hpad,Wpad))(layers[-1]))\n",
    "        layers.append(unet_block(layers[-1], kshape,channels))\n",
    "        layers.append(Cropping2D(cropping=(Hpad,Wpad))(layers[-1]))\n",
    "        \n",
    "        # Add DC block\n",
    "        layers.append(DC_block(layers[-1],mask,inputs,channels,kspace=kspace_flag))\n",
    "        kspace_flag = True\n",
    "    out = Lambda(ifft_layer)(layers[-1])\n",
    "    model = Model(inputs=[inputs,mask], outputs=out)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
